{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Assignment 4 of the course “Introduction to Machine Learning” at the University of Leoben.\n",
    "Author: Fotios Lygerakis\n",
    "Semester: SS 2022/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create the Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self):\n",
    "        self.coefficients = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "class LinearRegression(Predictor):\n",
    "    def fit(self, X, y):\n",
    "        # Add a column of ones to X for the bias term\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # Compute the coefficients using the normal equation\n",
    "        self.coefficients = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add a column of ones to X for the bias term\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # Predict the target variable\n",
    "        y_pred = X.dot(self.coefficients)\n",
    "        return y_pred\n",
    "\n",
    "class RidgeRegression(Predictor):\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Add a column of ones to X for the bias term\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # Compute the coefficients using the ridge regression formula\n",
    "        identity = np.eye(X.shape[1])\n",
    "        self.coefficients = np.linalg.inv(X.T.dot(X) + self.alpha * identity).dot(X.T).dot(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add a column of ones to X for the bias term\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # Predict the target variable\n",
    "        y_pred = X.dot(self.coefficients)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "class LassoRegression(Predictor):\n",
    "    def __init__(self, alpha=1, num_iters=10000, lr=0.001):\n",
    "        self.alpha = alpha\n",
    "        self.num_iters = num_iters\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Add a column of ones to X for the bias term\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # Set random seed for reproducibility\n",
    "        np.random.seed(42)\n",
    "\n",
    "        # Initialize the coefficients\n",
    "        self.coefficients = np.zeros(X.shape[1])\n",
    "\n",
    "        # Perform gradient descent to find the optimal coefficients\n",
    "        for _ in range(self.num_iters):\n",
    "            gradient = self.calculate_gradient(X, y)\n",
    "            self.coefficients -= self.lr * gradient\n",
    "\n",
    "    def calculate_gradient(self, X, y):\n",
    "        num_samples = X.shape[0]\n",
    "        errors = X.dot(self.coefficients) - y\n",
    "        gradient = X.T.dot(errors) / num_samples + self.alpha * np.sign(self.coefficients)\n",
    "        return gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Add a column of ones to X for the bias term\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # Predict the target variable\n",
    "        y_pred = X.dot(self.coefficients)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Data Preprocessing and Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # Handle missing values\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "    # Remove outliers\n",
    "    z_scores = np.abs((df - df.mean()) / df.std())\n",
    "    df = df[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "    # Normalize the data\n",
    "    df = (df - df.mean()) / df.std()\n",
    "\n",
    "    return df\n",
    "\n",
    "def train_test_split(X, y, test_size=0.2, random_state=42):\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Calculate the number of samples for the test set\n",
    "    num_test_samples = int(test_size * X.shape[0])\n",
    "\n",
    "    # Randomly shuffle the data\n",
    "    shuffled_indices = np.random.permutation(X.shape[0])\n",
    "    X_shuffled = X[shuffled_indices]\n",
    "    y_shuffled = y[shuffled_indices]\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train = X_shuffled[:-num_test_samples]\n",
    "    y_train = y_shuffled[:-num_test_samples]\n",
    "    X_test = X_shuffled[-num_test_samples:]\n",
    "    y_test = y_shuffled[-num_test_samples:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def load_data():\n",
    "    # Load the diabetes dataset\n",
    "    df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "    # Preprocess the dataset\n",
    "    df = preprocess(df)\n",
    "\n",
    "    # Split the features and target variable\n",
    "    X = df.drop(\"target\", axis=1).values\n",
    "    y = df[\"target\"].values\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Preprocess the dataset\n",
    "df = preprocess(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X_train, X_test, y_train, y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fit the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the linear regression\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)\n",
    "linear_regression_predictions = linear_regression.predict(X_test)\n",
    "linear_regression_coefficients = linear_regression.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the ridge regression\n",
    "ridge_regression = RidgeRegression(alpha=1)\n",
    "ridge_regression.fit(X_train, y_train)\n",
    "ridge_regression_predictions = ridge_regression.predict(X_test)\n",
    "ridge_regression_coefficients = ridge_regression.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the lasso regression\n",
    "lasso_regression = LassoRegression(alpha=1, num_iters=10000, lr=0.001)\n",
    "lasso_regression.fit(X_train, y_train)\n",
    "lasso_regression_predictions = lasso_regression.predict(X_test)\n",
    "lasso_regression_coefficients = lasso_regression.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "MSE: 0.45655844989286215\n",
      "R-squared: 0.49648680873991846\n",
      "\n",
      "Ridge Regression:\n",
      "MSE: 0.4538881699787352\n",
      "R-squared: 0.49943171351921944\n",
      "\n",
      "Lasso Regression:\n",
      "MSE: 0.9353291468042304\n",
      "R-squared: -0.03152304747942458\n",
      "Linear Regression Coefficients:\n",
      "[ 0.01352522 -0.01787645 -0.13537619  0.28798257  0.2314548  -0.55763991\n",
      "  0.28243652  0.14633152  0.21855619  0.43763473  0.07599883]\n",
      "\n",
      "Ridge Regression Coefficients:\n",
      "[ 0.01347934 -0.01716758 -0.13364481  0.28866895  0.2294461  -0.42512131\n",
      "  0.18070361  0.08770086  0.19869395  0.38786468  0.07691122]\n",
      "\n",
      "Lasso Regression Coefficients:\n",
      "[ 4.85115384e-04 -4.19393335e-04  2.72609196e-04  2.01691563e-04\n",
      "  4.17269671e-04 -1.58782240e-04 -2.65640671e-04 -3.34430014e-04\n",
      " -8.71494306e-05  4.99946716e-04  6.08148304e-04]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "linear_regression_predictions = linear_regression.predict(X_test)\n",
    "ridge_regression_predictions = ridge_regression.predict(X_test)\n",
    "lasso_regression_predictions = lasso_regression.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the models using metrics such as MSE and R-squared\n",
    "def evaluate(y_true, y_pred):\n",
    "    if y_pred is None:\n",
    "        return None, None\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    r2 = 1 - np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return mse, r2\n",
    "\n",
    "linear_regression_mse, linear_regression_r2 = evaluate(y_test, linear_regression_predictions)\n",
    "ridge_regression_mse, ridge_regression_r2 = evaluate(y_test, ridge_regression_predictions)\n",
    "lasso_regression_mse, lasso_regression_r2 = evaluate(y_test, lasso_regression_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Linear Regression:\")\n",
    "print(\"MSE:\", linear_regression_mse)\n",
    "print(\"R-squared:\", linear_regression_r2)\n",
    "\n",
    "print(\"\\nRidge Regression:\")\n",
    "print(\"MSE:\", ridge_regression_mse)\n",
    "print(\"R-squared:\", ridge_regression_r2)\n",
    "\n",
    "print(\"\\nLasso Regression:\")\n",
    "print(\"MSE:\", lasso_regression_mse)\n",
    "print(\"R-squared:\", lasso_regression_r2)\n",
    "\n",
    "# Print the coefficients\n",
    "print(\"Linear Regression Coefficients:\")\n",
    "print(linear_regression_coefficients)\n",
    "\n",
    "print(\"\\nRidge Regression Coefficients:\")\n",
    "print(ridge_regression_coefficients)\n",
    "\n",
    "print(\"\\nLasso Regression Coefficients:\")\n",
    "print(lasso_regression_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Top Features:\n",
      "s2\n",
      "s6\n",
      "bp\n",
      "s3\n",
      "\n",
      "Ridge Regression Top Features:\n",
      "s2\n",
      "s6\n",
      "bp\n",
      "s1\n",
      "\n",
      "Lasso Regression Top Features:\n",
      "s6\n",
      "age\n",
      "sex\n"
     ]
    }
   ],
   "source": [
    "# Get the absolute values of the coefficients\n",
    "linear_regression_abs_coefficients = np.abs(linear_regression.coefficients)\n",
    "ridge_regression_abs_coefficients = np.abs(ridge_regression.coefficients)\n",
    "lasso_regression_abs_coefficients = np.abs(lasso_regression.coefficients)\n",
    "\n",
    "# Find the indices of the top k features\n",
    "k = 4  # Number of top features to consider\n",
    "linear_regression_top_features = np.argsort(linear_regression_abs_coefficients)[-k:][::-1]\n",
    "ridge_regression_top_features = np.argsort(ridge_regression_abs_coefficients)[-k:][::-1]\n",
    "lasso_regression_top_features = np.argsort(lasso_regression_abs_coefficients)[-k:][::-1]\n",
    "\n",
    "# Exclude the index of 'target' column if present\n",
    "target_index = df.columns.get_loc('target')\n",
    "linear_regression_top_features = linear_regression_top_features[linear_regression_top_features != target_index]\n",
    "ridge_regression_top_features = ridge_regression_top_features[ridge_regression_top_features != target_index]\n",
    "lasso_regression_top_features = lasso_regression_top_features[lasso_regression_top_features != target_index]\n",
    "\n",
    "# Print the top features for each model\n",
    "print(\"Linear Regression Top Features:\")\n",
    "for feature_idx in linear_regression_top_features:\n",
    "    print(df.columns[feature_idx])\n",
    "\n",
    "print(\"\\nRidge Regression Top Features:\")\n",
    "for feature_idx in ridge_regression_top_features:\n",
    "    print(df.columns[feature_idx])\n",
    "\n",
    "print(\"\\nLasso Regression Top Features:\")\n",
    "for feature_idx in lasso_regression_top_features[:k]:\n",
    "    print(df.columns[feature_idx])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
