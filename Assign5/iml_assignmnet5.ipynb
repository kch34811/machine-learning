{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Perceptron Algorithm for Classification of Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Define the perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the perceptron algorithm\n",
    "class MultiClassPerceptron:\n",
    "    def __init__(self, input_dim, output_dim, lr=0.01, epochs=1000):\n",
    "        self.W = np.random.randn(input_dim, output_dim)\n",
    "        self.b = np.zeros((1, output_dim))\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def forward(self, X):\n",
    "        # compute the logits\n",
    "        logits = np.dot(X, self.W) + self.b\n",
    "        return logits\n",
    "\n",
    "\n",
    "    def backward(self, X, y):\n",
    "        # compute the gradients\n",
    "        m = X.shape[0]\n",
    "        logits = self.forward(X)\n",
    "        softmax_output = self.softmax(logits)\n",
    "        grad_logits = softmax_output\n",
    "        grad_logits[range(m), y] -= 1\n",
    "        grad_logits /= m\n",
    "\n",
    "        # update weights and biases\n",
    "        dW = np.dot(X.T, grad_logits)\n",
    "        db = np.sum(grad_logits, axis=0)\n",
    "        self.W -= self.lr * dW\n",
    "        self.b -= self.lr * db\n",
    "\n",
    "    def softmax(self, X):\n",
    "        exp_scores = np.exp(X)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "        return probs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for epoch in range(self.epochs):\n",
    "            self.backward(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        logits = self.forward(X)\n",
    "        y_pred = np.argmax(logits, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "p = MultiClassPerceptron(input_dim=X_train.shape[1], output_dim=3, lr=0.01, epochs=1000)\n",
    "p.fit(X_train, y_train)\n",
    "predictions_train = p.predict(X_train)\n",
    "predictions = p.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron classification train accuracy 0.8833333333333333\n",
      "Perceptron classification accuracy 0.9\n"
     ]
    }
   ],
   "source": [
    "# evaluate train accuracy\n",
    "print(\"Perceptron classification train accuracy\", accuracy_score(y_train, predictions_train))\n",
    "print(\"Perceptron classification accuracy\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Non-linear feature transformation on the concrete compressive strength dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "\n",
    "def polynomial_features(X, degree):\n",
    "    X_poly = X.copy()\n",
    "    for d in range(2, degree + 1):\n",
    "        combinations = combinations_with_replacement(range(X.shape[1]), d)\n",
    "        for comb in combinations:\n",
    "            X_new = np.prod(X[:, comb], axis=1)\n",
    "            X_poly = np.column_stack((X_poly, X_new))\n",
    "    return X_poly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Non-linear feature transformation\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# load the concrete compressive strength dataset\n",
    "df = pd.read_excel('Concrete_Data.xls')\n",
    "\n",
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Concrete compressive strength(MPa, megapascals) ', axis=1), df['Concrete compressive strength(MPa, megapascals) '], test_size=0.2, random_state=42)\n",
    "\n",
    "# transform the features into second degree polynomial features\n",
    "X_train_poly_custom = polynomial_features(X_train.values, degree=2)\n",
    "X_test_poly_custom = polynomial_features(X_test.values, degree=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Train the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (train poly custom): 53.09\n",
      "Mean squared error (test poly custom): 55.59\n",
      "Mean squared error (train): 110.66\n",
      "Mean squared error (test): 95.98\n",
      "R^2 (train poly custom): 0.81\n",
      "R^2 (test poly custom): 0.78\n",
      "R^2 (train): 0.61\n",
      "R^2 (test): 0.63\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "lr_poly_custom = LinearRegression()\n",
    "lr = LinearRegression()\n",
    "# fit the model\n",
    "lr_poly_custom.fit(X_train_poly_custom, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "# predict values from the polynomial transformed features\n",
    "predictions_poly_custom_train = lr_poly_custom.predict(X_train_poly_custom)\n",
    "predictions_poly_custom = lr_poly_custom.predict(X_test_poly_custom)\n",
    "# predict values from the original features\n",
    "predictions_train = lr.predict(X_train)\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "# mean squared error\n",
    "print(\"Mean squared error (train poly custom): {:.2f}\".format(mean_squared_error(y_train, predictions_poly_custom_train)))\n",
    "print(\"Mean squared error (test poly custom): {:.2f}\".format(mean_squared_error(y_test, predictions_poly_custom)))\n",
    "print(\"Mean squared error (train): {:.2f}\".format(mean_squared_error(y_train, predictions_train)))\n",
    "print(\"Mean squared error (test): {:.2f}\".format(mean_squared_error(y_test, predictions)))\n",
    "\n",
    "# coefficient of determination (R^2)\n",
    "print(\"R^2 (train poly custom): {:.2f}\".format(r2_score(y_train, predictions_poly_custom_train)))\n",
    "print(\"R^2 (test poly custom): {:.2f}\".format(r2_score(y_test, predictions_poly_custom)))\n",
    "print(\"R^2 (train): {:.2f}\".format(r2_score(y_train, predictions_train)))\n",
    "print(\"R^2 (test): {:.2f}\".format(r2_score(y_test, predictions)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "RBFs on the California Housing Prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implement the rbf_kernel() function\n",
    "def rbf_kernel(X, centers, gamma):\n",
    "    diff = X[:, np.newaxis, :] - centers[np.newaxis, :, :]\n",
    "    norm = np.linalg.norm(diff, axis=2)\n",
    "    rbf = np.exp(-gamma * np.power(norm, 2))\n",
    "    return rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression on original data:\n",
      "MSE: 0.5558915986952438\n",
      "R^2: 0.5757877060324512\n",
      "\n",
      "Linear regression on RBF-transformed data:\n",
      "MSE: 0.3710644691311594\n",
      "R^2: 0.7168330839511811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the California Housing Prices dataset\n",
    "data = fetch_california_housing()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# Choose the number of centroids and the RBF kernel width\n",
    "num_centroids = 100\n",
    "gamma = 0.1\n",
    "\n",
    "# Randomly select the centroids from the training set\n",
    "np.random.seed(42)\n",
    "idx = np.random.choice(X_train_std.shape[0], num_centroids, replace=False)\n",
    "centroids = X_train_std[idx]\n",
    "\n",
    "# Compute the RBF features for the training and testing sets\n",
    "rbf_train = rbf_kernel(X_train_std, centroids, gamma)\n",
    "rbf_test = rbf_kernel(X_test_std, centroids, gamma)\n",
    "\n",
    "# Fit a linear regression model on the original and RBF-transformed data\n",
    "linreg_orig = LinearRegression().fit(X_train_std, y_train)\n",
    "linreg_rbf = LinearRegression().fit(rbf_train, y_train)\n",
    "\n",
    "# Evaluate the models on the testing set\n",
    "y_pred_orig = linreg_orig.predict(X_test_std)\n",
    "mse_orig = mean_squared_error(y_test, y_pred_orig)\n",
    "r2_orig = r2_score(y_test, y_pred_orig)\n",
    "\n",
    "y_pred_rbf = linreg_rbf.predict(rbf_test)\n",
    "mse_rbf = mean_squared_error(y_test, y_pred_rbf)\n",
    "r2_rbf = r2_score(y_test, y_pred_rbf)\n",
    "\n",
    "# Print the results\n",
    "print(\"Linear regression on original data:\")\n",
    "print(\"MSE:\", mse_orig)\n",
    "print(\"R^2:\", r2_orig)\n",
    "\n",
    "print(\"\\nLinear regression on RBF-transformed data:\")\n",
    "print(\"MSE:\", mse_rbf)\n",
    "print(\"R^2:\", r2_rbf)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **(Bonus)** Multilayer Perceptron Algorithm for Regression of Concrete Compressive Strength Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Download the Concrete Compressive Strength Dataset from the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download the Concrete Compressive Strength Dataset from the UCI Machine Learning Repository.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel('Concrete_Data.xls')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X = df.drop('Concrete compressive strength(MPa, megapascals) ', axis=1)\n",
    "y = df['Concrete compressive strength(MPa, megapascals) ']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Define the multilayer perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implement the functions in the MLP class\n",
    "class MLP:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, lr=0.01, epochs=1000):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(self.input_dim, self.hidden_dim)\n",
    "        self.b1 = np.zeros((1, self.hidden_dim))\n",
    "        self.W2 = np.random.randn(self.hidden_dim, self.output_dim)\n",
    "        self.b2 = np.zeros((1, self.output_dim))\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        # Calculate the activations of the hidden layer\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = np.tanh(self.z1)\n",
    "\n",
    "        # Calculate the activations of the output layer\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.z2\n",
    "\n",
    "    def backward_propagation(self, X, y):\n",
    "        # Calculate the gradient of the output layer\n",
    "        delta2 = self.a2 - y\n",
    "\n",
    "        # Calculate the gradient of the hidden layer\n",
    "        delta1 = np.dot(delta2, self.W2.T) * (1 - np.power(self.a1, 2))\n",
    "\n",
    "        # Calculate the gradients of the weights and biases\n",
    "        dW2 = np.dot(self.a1.T, delta2)\n",
    "        db2 = np.sum(delta2, axis=0, keepdims=True)\n",
    "        dW1 = np.dot(X.T, delta1)\n",
    "        db1 = np.sum(delta1, axis=0)\n",
    "\n",
    "        # Update the weights and biases using the gradients\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.loss = []\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            # Forward propagation\n",
    "            self.forward_propagation(X)\n",
    "\n",
    "            # Backward propagation\n",
    "            self.backward_propagation(X, y)\n",
    "\n",
    "            # Calculate the mean squared error\n",
    "            mse = mean_squared_error(y, self.a2)\n",
    "            self.loss.append(mse)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Forward propagation to predict the output\n",
    "        self.forward_propagation(X)\n",
    "        return self.a2.flatten()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/gimchaehyeon/Downloads/ML_course-main/assignment 5/iml_assignmnet5_unsolved.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mlp \u001b[39m=\u001b[39m MLP(input_dim\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], hidden_dim\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, output_dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m mlp\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "\u001b[1;32m/Users/gimchaehyeon/Downloads/ML_course-main/assignment 5/iml_assignmnet5_unsolved.ipynb Cell 27\u001b[0m in \u001b[0;36mMLP.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_propagation(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Backward propagation\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackward_propagation(X, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# Calculate the mean squared error\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma2)\n",
      "\u001b[1;32m/Users/gimchaehyeon/Downloads/ML_course-main/assignment 5/iml_assignmnet5_unsolved.ipynb Cell 27\u001b[0m in \u001b[0;36mMLP.backward_propagation\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward_propagation\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# Calculate the gradient of the output layer\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     delta2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ma2 \u001b[39m-\u001b[39;49m y\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# Calculate the gradient of the hidden layer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gimchaehyeon/Downloads/ML_course-main/assignment%205/iml_assignmnet5_unsolved.ipynb#X35sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     delta1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(delta2, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW2\u001b[39m.\u001b[39mT) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mpower(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma1, \u001b[39m2\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:2101\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   2098\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array_ufunc__\u001b[39m(\n\u001b[1;32m   2099\u001b[0m     \u001b[39mself\u001b[39m, ufunc: np\u001b[39m.\u001b[39mufunc, method: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39minputs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m   2100\u001b[0m ):\n\u001b[0;32m-> 2101\u001b[0m     \u001b[39mreturn\u001b[39;00m arraylike\u001b[39m.\u001b[39;49marray_ufunc(\u001b[39mself\u001b[39;49m, ufunc, method, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:263\u001b[0m, in \u001b[0;36marray_ufunc\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    262\u001b[0m \u001b[39m# for binary ops, use our custom dunder methods\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m result \u001b[39m=\u001b[39m maybe_dispatch_ufunc_to_dunder_op(\u001b[39mself\u001b[39;49m, ufunc, method, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    264\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m    265\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/ops_dispatch.pyx:113\u001b[0m, in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     68\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:112\u001b[0m, in \u001b[0;36mOpsMixin.__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__rsub__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__rsub__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, roperator\u001b[39m.\u001b[39;49mrsub)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:5639\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[1;32m   5638\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_SERIES(\u001b[39mself\u001b[39m, other)\n\u001b[0;32m-> 5639\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/base.py:1297\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1295\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m-> 1297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_result(result, name\u001b[39m=\u001b[39;49mres_name)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:3017\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   3013\u001b[0m     \u001b[39mreturn\u001b[39;00m (res1, res2)\n\u001b[1;32m   3015\u001b[0m \u001b[39m# We do not pass dtype to ensure that the Series constructor\u001b[39;00m\n\u001b[1;32m   3016\u001b[0m \u001b[39m#  does inference in the case where `result` has object-dtype.\u001b[39;00m\n\u001b[0;32m-> 3017\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(result, index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   3018\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[1;32m   3020\u001b[0m \u001b[39m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[1;32m   3021\u001b[0m \u001b[39m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:451\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    449\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    450\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m    453\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    454\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/construction.py:598\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    595\u001b[0m             subarr \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, subarr)\n\u001b[1;32m    596\u001b[0m             subarr \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[0;32m--> 598\u001b[0m subarr \u001b[39m=\u001b[39m _sanitize_ndim(subarr, data, dtype, index, allow_2d\u001b[39m=\u001b[39;49mallow_2d)\n\u001b[1;32m    600\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(subarr, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    601\u001b[0m     \u001b[39m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[1;32m    602\u001b[0m     dtype \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mdtype, dtype)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/construction.py:649\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[39mif\u001b[39;00m allow_2d:\n\u001b[1;32m    648\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m--> 649\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mData must be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    650\u001b[0m \u001b[39mif\u001b[39;00m is_object_dtype(dtype) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    651\u001b[0m     \u001b[39m# i.e. PandasDtype(\"O\")\u001b[39;00m\n\u001b[1;32m    653\u001b[0m     result \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39masarray_tuplesafe(data, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# Create an instance of the MLP class\n",
    "mlp = MLP(input_dim=X_train.shape[1], hidden_dim=10, output_dim=1, lr=0.01, epochs=1000)\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 36.8911071801165\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compare the results with the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 95.97548435337708\n"
     ]
    }
   ],
   "source": [
    "# Fit a linear regression model on the training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)\n",
    "y_pred_lr = linear_regression.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "print(\"Mean Squared Error (Linear Regression):\", mse_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
